{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekPnSpVugZmv"
      },
      "source": [
        "# Stable Diffusion (Colab + VS Code friendly)\n",
        "\n",
        "This notebook is a cleaned, minimal flow for running Stable Diffusion.\n",
        "- Install once\n",
        "- Verify GPU\n",
        "- Load model once\n",
        "- Generate images\n",
        "\n",
        "If you are connecting from VS Code to a Colab runtime, execution still happens on Colab's GPU."
      ],
      "id": "ekPnSpVugZmv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yj94ekNrgZmw"
      },
      "outputs": [],
      "source": [
        "print(\"Installing dependencies...\")\n",
        "!pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install diffusers transformers accelerate\n",
        "print(\"Done.\")"
      ],
      "id": "yj94ekNrgZmw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v-q18xZgZmw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "print(f\"Torch: {torch.__version__}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA OK: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"CUDA not available. In Colab, set Runtime > Change runtime type > GPU.\")"
      ],
      "id": "_v-q18xZgZmw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Qo-DU2SgZmw"
      },
      "outputs": [],
      "source": [
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Loading {model_id} on {device}...\")\n",
        "pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
        ")\n",
        "pipeline = pipeline.to(device)\n",
        "print(\"Model loaded.\")"
      ],
      "id": "7Qo-DU2SgZmw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PW3dWJErgZmw"
      },
      "outputs": [],
      "source": [
        "prompt = \"A high-quality photo of an astronaut riding a horse on the moon, cinematic, 4k\"\n",
        "print(f\"Prompt: {prompt}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    image = pipeline(prompt, num_inference_steps=25).images[0]\n",
        "\n",
        "image"
      ],
      "id": "PW3dWJErgZmw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCWpyU2bgZmx"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "text_input = widgets.Text(\n",
        "    value=\"A futuristic city at sunset with flying cars and neon lights\",\n",
        "    description=\"Prompt:\"\n",
        ")\n",
        "\n",
        "generate_button = widgets.Button(description=\"Generate Image\")\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_button_clicked(_):\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        print(f\"Generating: {text_input.value}\")\n",
        "        with torch.no_grad():\n",
        "            img = pipeline(text_input.value, num_inference_steps=25).images[0]\n",
        "        display(img)\n",
        "\n",
        "generate_button.on_click(on_button_clicked)\n",
        "display(text_input, generate_button, output_area)"
      ],
      "id": "tCWpyU2bgZmx"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}